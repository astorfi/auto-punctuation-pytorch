
Researchers at Arizona State and Wright State Universities are working on a new
computerized sight-assistant system for the blind called the iCare that consists of cameras mounted to glasses and a
laptop stuffed in a backpack (which we're sure blind people are going to be stoked to lug around with them all day).
The iCare, which can help a blind person read, search the web, recognize friends and family, and move throughout rooms,
works by transforming images into words and can answer questions like "What the hell is that?" or describe the scene in
one continuous long monologue (sounds like some people we know). It comes with a couple of specialized applications,
the iCare-Reader, which translates texts into words, and the iCare-Assitant, which uses software to verbalize
university course content. Another application destined for misuse is the iCare-Human Recognizer which has "a high
probability" of recognizing people in a database — though it can only really do so when the subject is utterly still
and has replicated the exact position and lighting of the picture of them in its database. The final component is the
iCare-SceneAnalyzer which can describes the user's surroundings in words, making it possible )(at least in theory)
to walk around with ease. Sounds a bit like a seeing side kick.




 