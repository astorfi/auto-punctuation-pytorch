
 

Ready to get hands-on in the danger zone -- from afar? That's precisely what an enterprising team of University of Massachusetts Lowell researchers are working to achieve with a little Redmond-supplied assistance. The Robotics Lab project, dubbed the Dynamically Resizing Ergonomic and Multi-touch (DREAM) Controller, makes use of Microsoft's Surface and Robotics Developer Studio to deploy and coordinate gesture-controlled search-and-rescue bots for potentially hazardous emergency response situations. Developed by Prof. Holly Yanco and Mark Micire, the tech's Natural User Interface maps a virtual joystick to a user's fingertips, delegating movement control to one hand and vision to the other -- much like an Xbox controller. The project's been under development for some time, having already aided rescue efforts during Hurricane Katrina, and with future refinements, could sufficiently lower the element of risk for first responders. Head past the break for a video demonstration of this life-saving research.
      

 

 
 